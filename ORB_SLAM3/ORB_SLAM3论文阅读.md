# ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM

#### ________________________________________论文阅读笔记 钟煜

#### $Abstract$摘要
本文介绍了ORB-SLAM3，这是第一个能够使用**针孔和鱼眼镜头**模型使用单目，立体和RGB-D相机执行视觉，视觉惯性和**多地图**SLAM的系统。  
> 针孔和鱼眼相机的缺点？  
> 立体相机即双目相机

第一个主要的新颖之处是**基于功能的紧密集成的视觉惯性SLAM系统**，即使在IMU初始化阶段，该系统也完全依赖于**最大后验（MAP）估计**。 结果是，该系统可以在各种大小，室内和室外环境中实时稳定运行，并且比以前的方法精确2到5倍。  
> 优点？  
> 最大后验与状态估计的过程：最小二乘解

第二个主要的新颖之处是多地图系统，该系统**依赖于具有改进召回率的新场所识别方法**。 多亏了它，ORB-SLAM3能够在很差的视觉信息中生存下来：当丢失时，它会启动一个新地图，当重新访问地图区域时，它将**与以前的地图无缝合并**。 与仅使用最后几秒钟信息的视觉里程计系统相比，ORB-SLAM3是第一个**能够在所有算法阶段重用所有先前信息**的系统。 这允许在包调整中包含可见的关键帧，即使它们在时间上相隔很远或者来自先前的映射会话，它们也可以提供较高的视差观测值，从而提高了准确性。
> 召回率曲线：闭环检测的评价指标  
> 对召回率如何改进？

我们的实验表明，在所有传感器配置中，ORBSLAM3均与文献中提供的最佳系统一样强大，并且准确性更高。 值得注意的是，我们的立体声惯性SLAM在EuRoC无人机上的平均精度达到3.6 cm，在TUM-VI数据集（代表AR / VR场景的设置）的室内快速手持运动下达到9 mm

## $I.INTRODUCTION$ 介绍
在过去的二十年中，仅使用摄像头或与惯性传感器结合使用的视觉同步定位和建图系统（SLAM）和视觉里程计（VO）的大量研究就产生了出色的系统，其准确性和鲁棒性不断提高。 现代系统依赖于最大后验（MAP）估计，**在视觉传感器的情况下，它对应于捆绑调整（BA），或者是基于特征的方法中将特征重投影误差最小化的几何BA，或者直接法将最小化一组选定像素的光度误差的光度BA**。
> SLAM14讲中的BA（图优化）：用于求解PnP   [BA优化](https://blog.csdn.net/liuzheng1/article/details/87928834)

随着最近集成了闭环技术的VO系统的出现，VO和SLAM之间的边界变得更加分散。视觉SLAM的目标是使用移动代理上的传感器来构建环境地图并实时计算该地图中代理的姿态。相比之下，VO系统将重点放在计算代理人的自我运动上，而不是在构建地图上。  SLAM映射的最大优点是它允许在BA中匹配并使用执行三种数据关联的先前观测值：

- 短期数据关联，匹配最近几秒钟内获得的地图元素。 这是大多数VO系统使用的唯一数据关联类型，一旦环境元素消失，它们便会忘记它们，即使系统在同一区域移动，也会导致连续的估计漂移。
- 中期数据关联，匹配接近相机的地图元素，这些相机的累积漂移仍然很小。 这些可以与短期观测相同的方式进行匹配和在BA中使用，并且当系统在映射区域中移动时允许零漂移。 与带回路检测的VO系统相比，它们是我们系统获得更好精度的关键。
- 长期数据关联，使用位置识别技术将观测值与以前访问过的区域中的元素进行匹配，而不管累积的漂移（环路检测）还是跟踪丢失（重定位）。长期匹配允许使用姿态图（PG）优化或更精确地使用BA重置漂移并校正循环。 这是中型和大型循环环境中SLAM精度的关键。

> 数据关联？ 原理、发生环节、作用

在这项工作中，我们以ORB-SLAM和视觉惯性SLAM为基础，是第一个能够充分利用短期，中期和长期利益的视觉和视觉惯性系统数据关联，**在映射区域中达到零漂移**。 在这里，**我们进一步迈出了提供多地图数据关联的一步，这使我们能够匹配和使用来自先前映射会话的BA地图元素，从而实现SLAM系统的真正目标：构建比以后可用于提供准确定位的地图**  
这本质上是系统论文，其最重要的贡献是ORB-SLAM3库本身，这是迄今为止最完整，最准确的视觉，视觉惯性和多地图SLAM系统（请参见表I)。ORB-SLAM3的主要新颖之处在于：

- **单眼和立体视觉惯性SLAM系统** 即使在IMU（惯性测量单元）初始化阶段，它也完全依赖于事后最大值（MAP）估计。 提出的初始化方法已在[6]中提出。在这里，我们添加了它与ORB-SLAM视觉惯性的集成，对立体惯性SLAM的扩展以及对公共数据集的全面评估。 我们的结果表明，即使在无环的序列中，单目和立体视觉惯性系统也比其他视觉惯性方法具有更高的鲁棒性和准确性。

> [仅惯性优化的视觉惯性初始化方法](https://arxiv.org/pdf/2003.05766.pdf)  
> **将视觉惯性初始化公式化为最佳估计问题**。  
> 完全视觉惯性BA是一个非线性的问题，困扰着局部极小值，这阻碍了收敛。将其拆分为一个完全可观察到的大规模视觉问题，然后是一个非常有效地解决的仅惯性优化阶段，从而为缓解局部极小问题的VI-BA提供了初始解决方案

- **高召回率的地点识别**。 许多最近的视觉SLAM和VO系统使用DBoW2词库解决了位置识别问题。  **DBoW2需要时间一致性，在检查几何一致性之前将三个连续的关键帧匹配到同一区域，以牺牲召回为代价提高精度**。 结果，系统在关闭循环和重用以前的映射时速度太慢。 **我们提出了一种新颖的位置识别算法，其中首先检查候选关键帧的几何一致性，然后再检查三个常见的关键帧的局部一致性，这在大多数情况下已在地图中。 这种策略以略高的计算成本为代价，提高了召回率，并使数据关联更紧密，从而提高了地图的准确性**。

- ORB-SLAM Atlas，第一个完整的多地图SLAM系统，能够处理单目和立体配置的视觉和视觉惯性系统。 该地图集可以表示一组未连接的地图，并将所有映射操作顺利应用到它们：位置识别，摄像机重新定位，环路闭合和准确的无缝地图合并。 这允许自动使用和组合在不同时间构建的地图，从而执行增量多会话SLAM。[10]中介绍了用于视觉传感器的ORBSLAM Atlas的初步版本。在这里，我们添加了新的位置识别系统，视觉惯性多地图系统及其对公共数据集的评估。
> [ORBSLAM-Atlas](https://blog.csdn.net/qq_40878688/article/details/105291348)  


- **抽象的相机表示形式，使SLAM代码与所使用的相机模型无关，并允许通过提供其投影，非投影和Jacobian函数来添加新模型**。我们提供了针孔[11]和鱼眼[12]模型的实现。
> 抽象的表现形式？ 雅克比函数意味着什么？

所有这些新颖性，再加上一些代码改进，使得ORB-SLAM3成为新的参考视觉和视觉惯性开源SLAM库，与文献中提供的最佳系统一样强大，并且准确性显着提高，如我们的实验结果所示。 第七节 我们还提供了单眼，立体，单眼惯性和立体惯性SLAM结果之间的比较，这对于从业者可能很感兴趣。

## $II.RELATED \ WORK$ 相关工作(目前具有代表性的SLAM)
表I总结了最具代表性的视觉和视觉惯性系统，显示了用于估算和数据关联的主要技术。 对于现代系统，表中包括的定性准确性和鲁棒性等级基于第七部分中报告的比较，对于经典系统，基于文献[2]，[52]中的先前比较。
### $A. Visual-SLAM$
**MonoSLAM** 首先解决了单眼SLAM，使用了扩展卡尔曼滤波以及Shi-Tomasi角点，这些点在后续图像中通过相关性进行引导搜索而被跟踪。在使用保证特征匹配具有一致性的技术后，中期数据关联得到了明显的改善，从而实现了手持式的SLAM.  

相比之下，基于关键帧的方法仅使用几个选定的帧来估计地图，从而丢弃来自中间帧的信息。 这允许以关键帧速率执行成本更高但更准确的BA优化。 最具代表性的系统是**PTAM，它将摄像机跟踪和映射划分为两个并行线程**。**对于相同的计算成本，基于关键帧的技术比滤波更准确**，成为视觉SLAM和VO的黄金标准。 大型单眼SLAM在中使用滑动窗口BA实现，在[58]中使用双窗口优化和可视性图实现。  

在这些思想的基础上，**ORB-SLAM使用ORB功能，其描述符提供短期和中期数据关联，构建可视性图以限制跟踪和映射的复杂性，并执行闭环 使用词袋库DBoW2进行重新定位，从而实现长期数据关联**。 迄今为止，这是唯一集成了三种类型数据关联的可视SLAM系统，我们认为这是其出色准确性的关键。 在这项工作中，我们使用新的Atlas系统提高了它在纯视觉SLAM中的鲁棒性，该系统可在丢失跟踪时启动新地图，并使用新的高召回地点识别方法在循环场景中提高了准确性。
> [ORB特征](https://blog.csdn.net/zouzoupaopao229/article/details/52625678)
> 文献参考：ORB:An Efficient Alternative to SIFT or SURF 将FAST特征点检测方法（最快的特征点提取方法，一定的尺度不变性和旋转不变性）与BRIEF特征描述子结合

**直接方法不提取特征，而是直接使用图像中的像素强度，并通过最小化光度误差来估计运动和结构**。 LSD-SLAM能够使用高梯度像素构建大规模的半密集地图。 但是，地图估计被简化为姿势图，比PTAM和ORB-SLAM的准确性更低。 混合系统SVO提取FAST特征，使用直接方法来跟踪特征以及帧之间的具有非零强度梯度的任何像素，并使用重投影误差来优化相机轨迹和3D结构。SVO非常高效，但是作为纯VO方法，它仅执行短期数据关联，这限制了其准确性。 **直接稀疏测距法DSO能够在点检测器性能较差的情况下计算出准确的相机姿态，从而增强了低纹理区域或对模糊图像的鲁棒性。 它引入了局部光度学BA，可同时优化7个最近关键帧的窗口和点的反深度**。 这项工作的扩展包括立体，使用功能和DBoW2的闭环以及视觉惯性测距法。 直接稀疏映射DSM引入了在直接方法中重用地图的想法，显示了中期数据关联的重要性。 在所有情况下，缺乏短期，中期和长期数据关联的集成都会导致其准确性低于我们的建议（请参见第七部分）。
> DSO(Direct Sparse Odometry, 直接稀疏里程计) [DSO解读](https://blog.csdn.net/weixin_41803874/article/details/84197226)  
> DSM(Direct Sparse Mapping, 直接稀疏映射) [对DSO的优化，DSM解读](https://blog.csdn.net/OKasy/article/details/104913105)

> 数据关联方式
> - 直接法：VI-DSO, ROVIO
> - 描述子：ORB-SLAM, OKVIS
> - KLT跟踪:BASALT, VINS-Fusion, Kimera
> - 帧间相关性:MSCKF, MonoSLAM(精度较低)

### $B. Visual-Inertial \ SLAM$
视觉传感器和惯性传感器的组合可为 质量较差的纹理，运动模糊和遮挡提供鲁棒性，并且在单眼系统的情况下，使尺度可观察。
紧密耦合方法的研究可以追溯到MSCKF，其中通过**特征边缘化**避免了特征数量上的EKF二次成本。 最初的系统在[34]中得到完善，并在[35],[36]中扩展到立体。第一个基于关键帧和束调整的紧密耦合视觉里程计系统是OKVIS，它也能够使用单眼和立体视觉。虽然这些系统依赖功能，但ROVIO使用直接数据关联为EFK带来了光度误差。

ORB-SLAM-VI首次提出了一种视觉惯性SLAM系统，该系统能够在短期，中期和长期数据关联中重用地图，并将其用于基于IMU的准确本地视觉惯性BA中预整合。 但是，其IMU初始化技术太慢，耗时15秒，这损害了鲁棒性和准确性。 在[63]，[64]中提出了一种更快的初始化技术，该技术基于一种封闭形式的解决方案，可以共同获取比例尺，重力，加速度计偏差和初始速度以及视觉特征深度。 至关重要的是，它们**忽略了IMU噪声属性，并最小化了空间点的3D误差，而不是其重投影误差**，这是基于特征的计算机视觉的黄金标准。 我们以前的工作[65]表明，这**会导致较大的不可预测的错误**。

VINS-Mono是一个非常准确和强大的单眼球里程计系统，使用DBoW2和**4 DoF姿态图优化**以及地图合并实现闭环。 使用Lucas-Kanade跟踪器执行特征跟踪，它比描述符匹配要健壮得多。 在VINS-Fusion中，它已扩展到立体和立体惯性。  Kimera是一种新颖的杰出的度量-语义映射系统，但其度量部分包括立体惯性测距，DBoW2闭环和姿态图优化，实现了与VINS-Fusion相似的精度。 最新的BASALT是一种立体视觉惯性里程计系统，该系统从视觉惯性里程计中提取非线性因素以在BA中使用它们，并关闭与ORB功能匹配的回路，从而实现了非常好的精度。

最近，VI-DSO将DSO扩展到视觉惯性里程计。他们提出了一种捆绑调整，将惯性观测与所选高梯度像素中的光度误差结合在一起，从而提供了非常好的准确性。 随着高梯度像素中信息的成功利用，质地较差的场景区域中的鲁棒性也得到增强。他们的初始化方法依赖于视觉惯性BA，并花费20-30秒的时间在1％的比例误差内收敛。在这项工作中，我们以ORB-SLAM-VI为基础，并将其扩展为立体惯性SLAM。我们提出了一种基于最大后验（MAP）估计的新颖快速初始化方法，该方法适当考虑了视觉和惯性传感器的不确定性，并在2秒钟内以5％的误差估算真实比例，在15秒钟内收敛为1％的比例误差。上面讨论的所有其他系统都是视觉惯性测距法，其中一些系统通过闭环扩展，并且缺乏使用中期数据关联的能力。 我们相信，加上我们快速精确的初始化，这是即使在没有循环的序列中，系统始终如一地获得更高精度的关键。

###　$C. Multi-Map \ SLAM$
[Unified loop closing and recovery for
real time monocular SLAM]在滤波方法中首次提出了通过地图创建和融合增加鲁棒性以跟踪勘探过程中的损失的想法。 第一个基于关键帧的多地图系统是[Video-rate localization in mul-
tiple maps for wearable augmented reality]，但是地图初始化是手动的，并且该系统无法合并或关联不同的子地图。 作为协作制图系统的组成部分，已经研究了多地图功能，它具有几个制图代理和一个仅接收信息的中央服务器[69]或像C2TAM中那样具有双向信息流。MOARSLAM为协作多设备SLAM提出了一个健壮的无状态客户端服务器体系结构，但是重点是软件体系结构，而不是报告准确性结果。

最近，CCM-SLAM提出了一种基于ORB-SLAM的具有双向信息流的多无人机分布式多图系统。他们的重点是克服有限带宽和分布式处理的挑战，而我们的重点是准确性和鲁棒性，从而在EuRoC数据集上取得明显更好的结果。ORB-SLAMM还提出了ORB-SLAM2的多图扩展，但是在我们执行无缝图合并时，将子图保持为分离的实体，从而构建了更准确的全局图。

VINS-Mono是一种视觉里程计系统，具有闭环和多地图功能，这些功能依赖于位置识别库DBoW2。我们的实验表明，由于我们具有使用中期数据关联的能力，因此在EuRoc数据集的单眼-惯性单会话操作中，ORB-SLAM3的准确度是VINS-Mono的2.6倍。

我们的Atlas系统也建立在DBoW2的基础上，但提出了一种新颖的高召回地点识别技术，并使用本地BA执行更详细，准确的地图合并，在EuRoC的多会话操作中，其精度比VINS-Mono高3.2倍 。

## $III.SYSTEM \ OVERVIEW$ 系统概览
![Main system components of ORB-SLAM3](/home/fatcat/Desktop/graduate_project/Literature/Pic_in_Literature/Main_system_components_of_ORB-SLAM3.png)

ORB-SLAM3建立在ORB-SLAM2和ORB-SLAM-VI之上。 它是一个完整的多地图和多会话系统，可以使用针孔和鱼眼摄像头模型在具有单眼，立体声或RGB-D传感器的纯视觉或视觉惯性模式下工作。 图1显示了主要的系统组件，这些组件与ORB-SLAM2的组件具有一些重要的新颖之处，并在下面进行了总结：

- Atlas是由一组**未连接的地图组成的多地图**表示。有一个活动地图，**跟踪线程在其中定位传入的帧，并由本地映射线程不断优化并与新的关键帧一起增长**。我们将地图集中的其他地图称为non-active地图。系统将建立一个独特的关键帧DBoW2数据库，该**数据库用于重新定位，循环关闭和地图合并**。
> Atlas地图集能够无缝连接，实现重定位、回环检测、地点识别等功能。当每一个新的视觉帧进入流程，跟踪线程立即追踪并定位新一帧的位姿。地图集本身也随着时间逐步优化且会将新的视觉帧经过挑选作为关键帧。

- **跟踪线程处理传感器信息，并实时计算当前帧相对于活动地图的姿态，利用最小化重投影误差的方式实现位姿的最大后验估计MAP。它还决定当前帧是否成为关键帧。在视觉惯性模式下，通过在优化中包括惯性残差来估算车速和IMU偏差。当跟踪丢失时，跟踪线程会尝试在所有地图集的地图中重新定位当前帧。** 如果重新定位，则恢复跟踪，并根据需要切换active地图。否则，在一定时间后，活动地图将存储为non-active地图，并从头开始初始化新的活动地图。
> 旧的地图的正确性不会被局部定位的失败影响，新旧地图之间的位姿变换关系不确定性也有希望被之后的共视减小或者消除。

- **局部建图线程将关键帧和点添加到活动地图，删除多余的关键帧，并使用视觉或视觉惯性束调整来调整地图，并在接近当前帧的关键帧的本地窗口中操作。** 此外，在惯性情况下，IMU参数由映射线程使用我们新颖的MAP估计技术初始化和完善。
- **回环和地图合并线程：当每一个关键帧被插入，地点识别都被启动，这一关键帧被和整个Atlas地图集关键帧进行比较，如果检测到两关键帧是同一地点，分为两种情况：若被召回帧是当前的active地图中的一部分，则需要进行loop correction回环矫正，在回环矫正之后，Full BA在另一个线程中被悄悄进行，全局位姿图得到优化，整体的地图一致性得到了提升；若被召回帧是属于一个non-active的map，两个地图则会被合并成一个地图并将大地图设置为当前的active地图。这一过程和跟踪并行，不会影响跟踪的实时性**。

> 各线程功能概述。三大线程：**Tracking, Local Mapping, Loop&Map Merging**

## $IV.CAMERA \ MODEL$ 相机模型
ORB-SLAM在所有系统组件中**均采用针孔照相机模型**。 我们的目标是通过提取与相机模型相关的所有属性和功能（投影和非投影功能，雅可比等）到单独的模块中，从整个SLAM管道中提取相机模型。这使得我们的系统通过提供相应的摄像头模块可以使用任何摄像头型号。 在ORB-SLAM3库中，除了针孔模型外，我们还提供了Kannala-Brandt鱼眼模型。但是，相机模型抽象提出了一些需要解决的困难，下面将进行讨论。
### $A. Relocalization$ 重定位
强大的SLAM系统需要能够在跟踪失败时重新定位相机。ORB-SLAM通过基于ePnP算法设置一个PnP解算器来解决重定位问题，该算法在其所有公式中均假设使用经过标定的针孔照相机。 为了跟进我们的方法，我们需要一种PnP算法，该算法独立于所使用的相机模型而工作。 因此，我们采用了最大似然PnP算法（MLPnP），因为它使用投影射线作为输入，因此与相机模型完全分离。 相机模型仅需要提供从像素到投影射线的反投影功能，即可使用重新定位。
> [ePnP求解PnP问题](https://www.tugraz.at/fileadmin/user_upload/Institute/ICG/Images/team_lepetit/publications/lepetit_ijcv08.pdf)  
> [MLPnP算法](http://www.ipf.kit.edu/downloads/2016-MLPnP_congress.pdf) 提供一个将像素反投影为光束的unprojection公式以及相应像素点的坐标就可以求解相机的位姿

### $B. Non-rectified \ Stereo \ SLAM$ 未标定的双目SLAM
大多数双目SLAM系统都假设对双目帧进行了矫正，即，**使用相同的焦距将两个图像转换为针孔投影，并且图像平面共面，并且与水平对极线对齐，这样一幅图像中的特征可以通过查看另一张图片中的同一行可以轻松进行匹配**。 然而，校正后的双目图像的假设是非常严格的，并且在许多应用中不适合也不可行。 例如，矫正不同的双目对或双目鱼眼镜头将需要进行严格的图像裁剪，从而失去了大视场的优势：更快的环境建图和对遮挡的更好鲁棒性。
出于这个原因，我们的系统不依赖于图像标定，而是将双目相机视为两个具有以下功能的单目相机：
1) 两个单目相机具有固定位姿变化SE(3)
2) 两个相机帧之间存在较大的共视区域  

这些限制条件使我们能够有效地评估地图的尺度信息，通过介绍三角化新地标和BA优化时的信息。遵循这个想法，我们的SLAM估算了6自由度的刚体姿态，其参考系统可以位于其中一个摄像机或IMU传感器中，并代表刚体姿态的摄像机。

**为了利用双目的优势，如果两个相机之间存在共视区域，这一区域的特征点可以在第一次被看见的时候被三角化，且尺度的不确定性被双目SE3的尺度信息所消除。在没有共视的区域，特征点依旧按照多视图几何的方式进行三角化**。

##  $V. Visual-Inertial \ SLAM$ 视觉惯性SLAM
ORB-SLAM-VI是第一个能够重用地图的真正的视觉惯性SLAM系统。但是，它仅限于针孔单眼相机，并且初始化速度太慢，在某些具有挑战性的场景中失败。在这项工作中，我们基于ORB-SLAM-VI提供了快速准确的IMU初始化技术，以及具有针孔和鱼眼摄像头的单眼惯性和双目惯性SLAM的开源SLAM库。
### $A. Fundamentals$ 基本原理
在纯视觉SLAM中，估计状态仅包含当前的相机位姿。在惯性视觉SLAM中，需要计算额外的变量。如机器人位姿(body pose) $T_i=[R_i, p_i]\in SE(3)$，世界坐标系下的IMU速度$v_i$，陀螺仪偏差$b^g_i$和加速度计偏差$b^a_i$，这些量都假设根据布朗运动规律变化。一起构成的状态向量如下：
$$S_i={T_i,v_i,b^g_i,b^a_i}$$  
对于视觉惯性SLAM，按照[Visual-inertial-aided navigation for high-
dynamic motion in built environments without initial conditions](http://static.tongtianta.site/paper_pdf/94d7a118-9234-11e9-8985-00163e08bb86.pdf)所提出的理论和在[On-Manifold Preintegration for Real-Time
Visual-Inertial Odometry](https://www.cc.gatech.edu/~dellaert/pubs/Forster16tro.pdf)[62]中提出的流型，对连续视觉帧$i$和$i+1$之间的IMU测量值进行了预积分。获得了对旋转量、速度和位置的预积分值，分别表示为 $\Delta R_{i,i+1},\Delta v_{i,i+1},\Delta p_{i,i+1}$以及整个测量向量的信息矩阵 $\Sigma I_{i,i+1}$。给定这些预积分项和状态项$S_i$和$S_{i+1}$，采用文献[62]中对惯性残差$r_{I_{i,i+1}}$:
$$r_{I_{i,i+1}}=[r_{\Delta R_{i,i+1}},r_{\Delta v_{i,i+1}},r_{\Delta p_{i,i+1}}]$$
$$r_{\Delta R_{i,i+1}}=Log(\Delta R^T_{i.i+1}R^T_iR_{i+1})$$
$$r_{\Delta v_{i,i+1}}=R^T_i(v_{i+1}-v_i-g\Delta t_{i,i+1})-v_{i,i+1}$$
$$r_{\Delta p_{i,i+1}}=R^T_i(p_j-p_i-v_i\Delta t-\frac{1}{2}g\Delta t^2)-\Delta p_{i,i+1}$$  
除了惯性残差之外，同时使用第$i$帧图像和在位置$x_j$的3D点$j$计算重投影误差：
$$r_ij=u_ij-\Pi (T_CBT^{-1}_i)\bigoplus x_j$$
式中 $\Pi:\mathbb{R}^3\rightarrow\mathbb{R}^n$是对应相机函数的投影函数，$u_ij$是图像$i$对点$j$的观测，具有信息矩阵 $\Sigma_ {i,i+1}$。$T_CB \in SE(3)$ 表示从机器人IMU到相机（左或右）的刚体变换，可以从相机标定中获得(李群SE(3)在三维空间上的转换运算)。 $\bigoplus$ 是SE(3)在 $\mathbb{R}^3$元素上的变换操作。

![factor_graph](/home/fatcat/Desktop/graduate_project/Literature/Pic_in_Literature/Factor_graph.png)

**结合惯性和视觉残差项，可以将视觉惯性SLAM视为基于关键帧的最小化问题**。 给定一组$k+1$个关键帧及其状态量 $\overline{S}_k={S_0\dots S_k}$，以及一组l个3D点及其状态量$X={x_o\dots x_{l-1}}$，视觉惯性优化问题可以表示为  
$${\displaystyle \min_{\overline{S}_k,\chi}}(\sum^k_{i=1}{||r_{I_{i-1,i}}||}^2_{\sum{I_{i,i+1}}}+\sum^{l-1}_{j=0}\sum_{i \in K^j}\rho Hub(||r_{ij}||_{\sum_{ij}}))(4)$$

式中，$K^j$是观察3D点j的关键帧集。这种优化可以概括为图2a所示的因子图。**对于重投影误差，采用鲁棒的Huber核$pHub$来减少虚假匹配的影响**，对于惯性残差则不需要，因为数据的关联缺失并不存在。这种优化需要提高跟踪和建图的效率，更重要的是，需要良好的初始化种子才能收敛到准确的情况。
> 分别将两个残差的信息矩阵加权马氏距离进行求和最小化即是最终的损失函数。在优化时，调整路标点的三维坐标以及机器人状态（R，p，v，q，b）使目标损失函数最小

### $B. IMU \ Initialization$ 初始化
此步骤的目标是为惯性变量获取良好的初始值：机器人速度，重力方向和IMU偏差。 诸如VI-DSO之类的某些系统尝试从头解决视觉惯性BA，避开特定的初始化过程，获得惯性参数的缓慢收敛（最多30秒）。  
在这项工作中，我们基于以下三个主要见解提出了一种快速而准确的初始化方法：

- 纯单目SLAM可以提供非常准确的初始地图，其主要问题是尺度未知。**首先解决纯视觉问题将增强IMU初始化。**
- 当尺度作为一个明确的优化变量，而不是BA的隐式变量时，收敛地更快。
> 尺度应该作为一个单独的优化变量而不是作为一个隐含变量存在于逆深度、相机位移等包含尺度的量中

- 在IMU初始化过程中忽略传感器不确定性会产生较大的不可预测的错误

因此，在适当考虑传感器不确定性的情况下，我们将IMU初始化表示为MAP估计问题，分为三个步骤：
> 什么情况下可以用MAP估计？MAP估计的优势？

1) **仅视觉MAP估计**： 初始化纯单目视觉SLAM并在2秒内运行，以4Hz频率插入关键帧，将得到一个k=10个相机姿态和数百个点组成的放大比例(up-to-scale)地图，其使用了仅视觉的BA优化。（如图2b）这些姿态将转化为机器人参考，获得轨迹 $\overline{T}_{0:k}=[R,\overline{p}]_{0:k}$，其中横条代表比例缩放变量
2) **仅惯性MAP估计**：在这一步中，我们的目的是仅使用轨迹 $\overline{T}_{0:k}$和这些关键帧之间的惯性测量值来获得惯性变量的最佳估计（就MAP估计而言）。这些惯性变量可以堆叠在仅惯性状态向量中：
$$y_k=\{{s,R_{wg},b,\overline{v}_{0:k}}\}(5)$$
其中$s\in \mathbb{R}^+$ 是仅视觉解的比例因子；$R_{wg}\in S0(3)$ 是重力方向，可以用两个角度表示。在世界参考系中，重力矢量是 $g=R_{wg}g_I$，其中$g_I=(0,0,G)^T$是重力大小；$b=(b^a,b^g)\in \mathbb{R}^6$是在初始化期间假定为恒定的加速度计和陀螺仪偏置。$\overline{v}_{0:k}\in \mathbb{R}^3$是从第一个关键帧到最后一个关键帧的比例速度(up-to-scale body velocities),初始化时是通过 $\overline{T}_{0:k}$ 估计的。此时，我们仅考虑观星测量的合集 $I_{0:k}\doteq\{I_{0,1}\dots I_{k-1,k}\}$。因此，我们可以描述一个MAP估计问题，其中要最大化的后验分布为：
 $$p(y_k|I_{0:k})\propto p(I_{0:k}|y_k)p(y_k)(6)$$  
> 贝叶斯公式，后验=似然×先验。括号内为IMU测量值，下一步用最大似然

式中，$p(I_{0:k}|y_k)$ 代表似然性，$p(y_k)$ 代表先验性。考虑到测量的独立性，仅惯性MAP估计问题可以改写为：
$$y^*_k=\displaystyle arg\max_{y_k}(p(y_k)\prod_{i=1}^kp(I_{i-1,i}|s,g_{dir},b,\overline{v}_{i-1},\overline{v}_i))(7)$$
取负对数并假设IMU预积分和先验分布满足高斯误差，最终会变成以下的优化问题：
$$y^*_k=\displaystyle arg\min_{y_k}(||r_p||^2_{\Sigma_p}+\sum^k_{i=1}||r_{I_{i-1,i}}||^2_{\Sigma_{I_{i-1,i}}})(8)$$
图2c中表示的这种优化方法与等式4的**不同之处在于不是包括视觉残差，而是在于用来加强IMU偏置的先验残差$r_p$应该接近零**，其协方差由IMU特性给出。  
当在流型上进行优化时，我们需要定义一个retraction以在优化过程中更新重力方向估计（更新李群）：
$$R^{new}_{wg}=R^{old}_{wg}Exp(\delta\alpha_g,\delta\beta_g,0)(9)$$  
Exp(.)是从$so(3)$到$SO(3)$的指数映射。为了确保尺度因子在更新期间保持正值，将其重新定义为
$$s^{new}=s^{old}exp(\delta s)(10)$$
一旦仅惯性的优化完成，关键帧的姿态和速度就会以估计的尺度缩放3D地图点，并旋转以使z轴与估计的重力方向对齐。更新偏置并重复IMU的预积分以减少将来的线性化误差。  

3) **视觉惯性联合MAP**
一旦我们对惯性和视觉参数有了一个很好的估计，就可以进行视觉-惯性联合优化，以进一步完善解决方案。 该优化可以表示为图2a，但是对于所有关键帧具有共同的偏差，并且包括与仅惯性步骤相比相同的先验信息。

我们在EuRoC数据集上进行的详尽初始化实验表明，这种初始化非常有效，在2秒的轨迹上达到5％的比例误差。 为了改善初始估计，在初始化后的5到15秒内执行视觉惯性BA，如第VII节所示，收敛到1％的尺度误差。在获得这些BA之后，我们说地图已经成熟mature，这意味着比例，IMU参数和重力方向已被准确估计。  
我们的初始化比解决一组代数方程的联合初始化方法更加准确，并且比ORB-SLAM-VI中使用的初始化（需要15秒才能获得第一次尺度估计）要快得多。 估计或VI-DSO中使用的估计，首先会产生巨大的刻度误差，并且需要20-30秒才能收敛到1％的误差。  
通过将尺度因子固定为1并将其从仅用于惯性的优化变量中删除，从而增强了其收敛性，我们已经轻松地将单目惯性初始化扩展为双目惯性。

### $C. Tracking \ and \ Mapping$ 跟踪和建图
对于跟踪和建图，我们采用单目视觉惯性SLAM中提出的方案。跟踪解决了简化的视觉惯性优化，其中仅优化了最新两帧的状态，而路标点保持固定。  
在建图时，尝试解决等式4的整个优化问题对于大型地图而言将是棘手的。**我们使用关键帧及其点的滑动窗口作为可优化变量**，包括可见的关键帧，但保持不变。  
在某些特定情况下，当慢动作不能提供良好的惯性参数可观察性时，初始化可能仅在15秒内无法收敛到精确解。为了在这种情况下获得鲁棒性，我们基于改进的仅惯性优化提出了一种新颖的尺度优化技术，其中包括所有插入的关键帧，但尺度和重力方向是唯一要估计的参数（图2d）。 请注意，在那种情况下，恒定偏差的假设将是不正确的。 相反，我们使用每个帧的估计值，然后对其进行修复。 此优化的计算效率非常高，它每十秒钟在局部建图线程中执行一次，直到建图自初始化以来具有100个以上的关键帧或超过75秒为止。

### $D. Robustness \ to \ tracking \ loss$ 追踪损失的稳健性
在纯视觉SLAM或VO系统中，暂时的相机遮挡和快速运动会导致视觉元素丢失跟踪，从而使系统丢失。ORB-SLAM率先使用了**基于词袋位置识别的快速重定位技术**，但事实证明它们不足以解决EuRoC数据集中的困难序列[3]。当跟踪少于15个点的地图时，我们的视觉惯性系统将进入视觉丢失状态，并在两个阶段实现鲁棒性：

- 短期丢失：根据IMU读数估算当前的body pose，并在估算的摄像机姿态中投影地图点，并在较大的图像窗口中搜索匹配项。结果匹配包含在视觉惯性优化中。在大多数情况下，这可以恢复视觉跟踪。否则，在5秒钟后，我们进入下一个阶段。
- 长期丢失：如上所述，初始化了新的视觉惯性图，它成为活动(active)地图。

> 实际上跟踪问题就是最新两帧的VI-BA优化问题，而t-1帧路标点是fix的。在建图时，需要在滑动窗口和共视图里做一个范围更大的BA，以获得更高的地图准确性，参与建图BA优化的帧由于计算量限制不能把所有帧加进来，而是仅仅包含窗口内的帧and与当前帧有共同观测的帧。有的时候，初始化并不理想，这时候我们把头100帧或者前75s的keyframe全部纳入初始化优化阶段，用于获得一个较好的重力旋转向量和尺度。实际上这个过程就是“初始化不好的时候就让他初始化久一点”，但这一过程中只优化图2d框框外的变量。当跟踪过程中小于15个可辨认特征点时，进入visually lost即视觉丢失状态。并采用应对策略：从IMU估计当前位姿，并扩大滑动窗口的长度，将IMU获得的位姿以及当前帧特征点投影到这个大一点的滑动窗口中去寻找匹配。如果这一过程5s后仍没有成功重定位，则开启新的小地图，并将新图切换为active状态。

## $VI. MAP \ MERGING \ AND \ LOOP \ CLOSING$ 地图合并和回环检测(重点*)
跟踪和建图线程通常通过将地图点投影到估计的相机姿态并在仅几个像素的图像窗口中搜索匹配项，来常规地找到帧与活动地图(active map)之间的短期和中期数据关联。为了实现用于重定位和回环检测的长期数据关联，ORB-SLAM使用DBoW2词袋位置识别系统。最新的实现闭环的VO和SLAM系统也采用了这种方法（表I）。
>[Bags of Binary Words for Fast Place Recognition in Image Sequences词袋对图像序列的快速识别技术(DBoW2的使用)](http://webdiis.unizar.es/~dorian/papers/GalvezTRO12.pdf)
>[Fast Relocalization and Loop Closing in Keyframe-Based SLAM基于关键帧的快速重定位和回环检测技术](http://webdiis.unizar.es/~jdtardos/papers/2014_IEEE_ICRA_Mur_Tardos.pdf)

与跟踪不同，位置识别不是从对摄像机姿势的初始猜测开始的。相反，**DBoW2用其词袋矢量构建关键帧的数据库，并且给定查询图像能够根据其词袋有效地提供最相似的关键帧**。仅使用第一个候选对象，原始DBoW2查询就可以达到50-80％的精度和召回率。**为了避免误报会破坏地图，DBoW2实施了时间和几何一致性检查，将工作点的精度提高到100％，召回率达到30-40％**。至关重要的是，时间一致性检查至少在3个关键帧期间延迟了位置识别。 当尝试在我们的Atlas系统中使用它时，我们发现**这种延迟和较低的召回率经常是在相同或不同地图的重复区域中造成的**。  
在这项工作中，我们提出了一种新的位置识别算法，该算法可改善长期和多地图数据关联的召回率。**每当建图线程创建新的关键帧时，就会启动位置识别，以尝试检测与Atlas中已存在的任何关键帧的匹配。 如果找到的匹配关键帧属于活动地图，则执行回环关闭(loop closure)。否则，它是一个多地图数据关联，然后，将活动地图和匹配地图合并**。 作为我们方法的第二个新颖性，**一旦估计了新关键帧与匹配地图之间的相对位姿，我们就在共视图(covisibility graph)中定义了一个具有匹配关键帧及其邻居的局部窗口$local\ window$。 在此窗口中，我们集中搜索中期数据关联，从而提高了回环检测和地图合并的准确性**。 这两个新颖性说明了在EuRoC实验中，与ORB-SLAM2相比，ORB-SLAM3获得了更好的精度。 接下来说明不同操作的细节。
> ORB-SLAM3的创新点：
> 1) 回环检测和地图合并机制
> 2) 用在共视图local window上的一致性检测，代替了时间上的一致性

### $A. Place \ Recognition$ 场景识别
为了获得较高的召回率，对于每个新的活动关键帧，我们都会在DBoW2数据库中查询Atlas中的几个类似关键帧。为了达到100％的精度，每个候选对象都要经过几步几何验证。**所有几何验证步骤的基本操作包括：使用图像之间的汉明距离阈值，检查图像窗口内是否有一个ORB关键点，其描述子与地图点的ORB描述子匹配。** 如果在搜索窗口中有多个候选者，为了丢弃不明确的匹配项，我们检查到第二近匹配项的距离比(distance ratio to the second-closest match)。 我们的位置识别算法的步骤是：  
1) **DBoW2候选关键帧**。 我们使用活动关键帧$K_a$查询Atlas DBoW2数据库，以检索三个最相似的关键帧，但不包括与$K_a$共视的关键帧。 我们将每个用于位置识别的匹配候选者称为$K_m$。  
> 得到Ka的三个候选匹配帧

2) **本地窗口$local \ window$**。对于每一个$K_m$，我们定义一个本地窗口，其中包括$K_m$，其最佳共视关键帧以及它们所有观察到的地图点。  DBoW2直接索引提供了$K_a$中的关键点与本地窗口关键帧中的一组假定匹配(putative matches)。 对于每个2D-2D匹配项，我们还可以在其对应的地图点之间使用3D-3D匹配项。  
> 将Km、Km的n个最佳共视帧、所有这些帧看到的路标点放进local window里，通过词库袋的正向索引得到各个匹配点的2D匹配关系，从而建立匹配点的3D匹配关系。

3) **3D对齐变换**。 我们使用**RANSAC**计算出变换 $T_{am}$，它使 $K_m$局部窗口中的地图点与$K_a$的地图点更好地对齐。在纯单目或单目惯性中（当地图还不成熟时），我们计算$T_{am}\in Sim(3)$，否则计算$T_{am}\in SE(3)$ 。在这两种情况下，我们都使用**Horn算法**,该算法使用三个3D-3D匹配的最小集合来找到 $T_{am}$ 的每个假设。通过$T_{am}$将$K_a$中的地图点进行变换后，假定的匹配将在$K_a$中实现低于阈值的重投影误差，从而对该假设给予肯定的投票。如果超过一定的阈值，则选择具有更多投票的假设。
> 计算Km到Ka的一个相似变换Sim(3)（若尺度不确定）。为得到候选变换，把每个匹配的点对重投影误差计算出来，当小于一定的阈值，就对此变换投票，从而选出最好的位姿变换T

4) **引导匹配细化(Guided matching refinement)**。使用$T_{am}$ 转换本地窗口中的所有地图点，以找到与$K_a$中的关键点更多的匹配项。搜索也相反，在本地窗口的所有关键帧中查找$K_a$地图点的匹配项。使用找到的所有匹配，通过非线性优化优化$T_{am}$，其中**目标函数是双向重投影误差，并使用Huber影响函数为虚假匹配提供鲁棒性。 如果优化后的内部数超过阈值，则使用较小的图像搜索窗口启动第二次引导匹配和非线性细化**。
> 得到位姿变换T后，由于前面是基于采样计算的位姿变换，没有用到全部的特征点匹配信息，需要用上所有有用信息改善一下T.在local window里找所有与这帧图像中特征点匹配的路标,并使用双向转移误差作为目标函数.

5) **在三个共视的关键帧中进行验证**。为避免误报，DBoW2**等待位置识别在三个连续的关键帧中触发，从而延迟或丢失位置识别**。 我们的关键见解是，大多数时候，验证所需的信息已在地图中。 为了验证位置识别，我们在地图的活动部分中搜索了两个与$K_a$共视的关键帧，其中局部窗口中与点的匹配数超过阈值。 如果未找到，则使用新的传入关键帧进一步尝试进行验证，而无需再次触发词袋。**验证将持续到三个关键帧验证$T_{am}$ 或两个连续的新关键帧无法验证它为止**。
> 在Ka的active map中找到两个共视帧,然后看这两帧与local windows的匹配点数目是否超过阈值.**这一过程持续三帧成功或者连续两帧失败来作为验证成功失败的判断条件**.

6) **VI重力方向验证**。 在视觉惯性的情况下，如果活动图成熟，我们就可以估算出$T_{am}\in SE(3)$。 我们进一步检查俯仰角和滚转角是否低于阈值，以明确接受位置识别假设。

### $B. Visual \ Map \ Merging$ 纯视觉地图合并
当成功的位置识别在活动地图$M_a$中的关键帧$K_a$与来自Atlas $M_m$中存储的不同地图的匹配关键帧$K_m$之间产生多地图数据关联时，我们会使用对齐变换$T_{am}$，启动地图合并操作。 在此过程中，必须格外小心，以确保跟踪线程可以迅速重用$M_m$中的信息，以避免地图重复。 为此，我们建议将$M_a$地图引入$M_m$参考。 由于$M_a$可能包含许多元素，并且合并它们可能需要很长时间，因此合并分为两个步骤。 首先，在由$K_a$和$K_m$的邻居定义的缝合窗口(welding window)中执行合并，然后在第二阶段，通过位图优化将校正传播到合并图的其余部分。 合并算法的详细步骤为：
> 明确几个量  
$K_a$: 活动关键帧$active\ \ keyframe$  
$K_m$: 候选的匹配关键$matching \ candidate \ for \ place recognition$  
$T_{ma}$:位姿变换(对每个匹配的点对重投影误差计算出来,投票取最优)  
$M_a$:活动地图 (最新的地图)$active \ \ map$  
$M_m$:Atlas中存储的地图(被召回的地图)

1) **缝合窗口(Welding window assembly)**.缝合窗口包括$K_a$(活动关键帧)和其共视关键帧,$K_m$(Ka的候选匹配关键帧)和其共视关键帧,以及他们所有能观察到的地图点.在将它们包含在缝合窗口中之前,属于$M_a$(活动地图)的关键帧和地图点通过$T_{ma}$ 进行变换,使其相对于$M_m$对齐.
2) **合并地图(Merging maps)** 地图$M_a$和$M_m$融合在一起成为新的活动地图.为了删除重复的点.对$M_a$中的每个点都在$M_m$中寻找匹配项.对于每次匹配,$M_a$中的点都会删除,保留$M_m$中的点,以累积该删除点的所有观测值.由于发现了新的中期点数据关联,通过添加连接关键帧的边缘来更新共视图和基本图(the covisibility and essential graphs)
>  当发现Ka和Km的匹配发生在**不同小地图**之间,进行缝合.将Ka Km和其所有共视帧所有帧的特征点放入缝合窗口.**在将Ma(最新的地图)里面的特征点放进窗口前,将所有特征点通过Tma变换到Mm地图(被召回的地图)**.在地图缝合时,对两图中的重复点进行剔除.

3) **缝合束调整(Welding bundle adjustment)**.执行局部BA优化缝合窗口中来自$M_a$和$M_m$的所有关键帧（图3a）。为了确定尺度自由度，与$M_m$中共视的关键帧保持固定。优化完成后，缝合区域中包含的所有关键帧都可以用于相机跟踪，从而实现地图$M_m$的快速，准确重用。
4) **姿势图优化(Pose-graph optimization)**。使用整个合并图的基本图执行姿势图优化，同时将关键帧固定在缝合区域中.此优化将校正从缝合窗口传播到地图的其余部分。
> 缝合后进行优化,分为两块:1.缝合优化 2.整体优化  
**缝合优化**:将缝合窗口之外的部分进行固定,再在缝合窗口内部进行一个BA优化,至此缝合后的地图就可以用来追踪新的帧  
**整体优化**:为了提升窗口内外的一致性,利用利用地图缝合减小整体的累计误差,进行整体的位姿图优化.缝合窗口被固定,窗口外采用essential graph进行优化.回环矫正从缝合窗口传向整个地图,缝合优化完成.

![welding_BA](/home/fatcat/Desktop/graduate_project/Literature/Pic_in_Literature/welding_BA.png)
> 地图缝合因子图   
蓝色方块-重投影误差项 黄色方块-IMU预积分项 紫色方块-随机偏置

### $C. Visual-Inertial \ Map \ Merging$视觉惯性地图缝合
视觉惯性缝合算法与纯视觉情况相比，遵循相似的步骤。 修改了步骤1）和3）以更好地利用惯性信息：
1）**VI缝合窗(VI welding window assembly)**：如果活动图成熟(active map is mature)(尺度已知?)，我们将可用的$T_{ma}\in SE(3)$ 应用于图$M_a$，在其包括在缝合窗口之前。如果活动图还不成熟，我们使用可用的$T_{ma}\in Sim(3)$ 对齐$M_a$。  
2）**VI缝合束的调整(VI welding bundle adjustment)**：**活动关键帧$K_a$及其最新的5个临时关键帧的位置，速度和偏差作为可优化的对象**。 这些变量与IMU预积分项相关。对于地图$M_m$，我们进行相似的处理，包括$K_m$及其5个时间邻域的姿态，速度和偏差，如图3b所示。 对于$M_m$，包括紧接在本地窗口之前的关键帧，但是是固定的；而对于$M_a$，包括相似的关键帧，但其姿势仍然可以优化。所有这些关键帧看到的所有点以及观察这些点的关键帧姿势也都进行了优化。所有关键帧和点都通过重投影错误进行关联。
> 与纯视觉地图缝合的区别  
> 1) 如果active map is mature,按照纯视觉SLAM进行,如果not mature,说明尺度信息暂时不可靠,在缝合时需要用相似变换$Sim(3)$ 而不是$SE(3)$ (李代数中对应的变量数不同)将$M_a$中的点对齐到$M_m$
> 2) 变化图多了固定的偏置量和速度量

### $D. Loop \ Closing$回环
回环校正算法类似于地图合并，但是在这种情况下，与位置识别匹配的两个关键帧都属于活动地图。缝合窗口是由匹配的关键帧组装而成的，并且检测并融合了点重复项，从而在共视图和基本图(essential graph)中创建了新链接。 下一步是姿势图优化，以将回环校正传播到地图的其余部分。最后一步是在考虑回路闭合中期和长期匹配之后找到MAP估计值的全局BA。在视觉惯性的情况下，仅在关键帧的数量低于阈值时才执行全局BA，以避免巨大的计算成本。

## $VIII. CONCLUSIONS$结论
在ORB-SLAM,ORB-SLAM2,VI单目SLAM的基础上,这是最完整的视觉,视觉惯性和多地图SLAM开源库,集合了单目,双目,RGB-D,针孔和鱼眼相机.除了集成库本身以外,我们主要贡献是快速准确的IMU初始化技术以及多环节的地图合并功能,这些功能依赖于改进的召回率的新位置识别技术,并使ORB-SLAM3非常适合实际应用中的长期和大规模SLAM.  
我们的实验结果表明,ORB-SLAM3是第一个能够有效利用短期,中期,长期和多地图数据关联的视觉和视觉惯性系统,其准确性超出了现存系统的范围.同时,关于准确性,使所有这些类型关联的能力也超过其他系统,例如use direct methods of features,or perform keyframe marginalization for local BA,instead of assuming an outer set of satic keyframes as we do.  
关于鲁棒性,直接法在低纹理环境中可能更具鲁棒性,但仅限于短期和中期的数据关联.另一方面,匹配的特征描述子可以成功解决长期和多地图的数据关联.但与使用光度(photometric)信息的Lucas-Kanade相比,跟踪功能似乎不那么可靠. An interesting line of research could be developing
photometric techniques adequate for the four data association problems. We are currently exploring this idea for map building from endoscope images inside the human body.  
对于四种不同的传感器配置，毫无疑问，双目惯性SLAM提供了最可靠，最准确的解决方案。此外，惯性传感器允许以IMU速率估算姿势，IMU速率比帧速率高几个数量级，这是某些用例的关键特征。对于双目摄像机由于其更大的体积，成本或处理要求而不受欢迎的应用程序，您可以使用单目惯性而不会在鲁棒性和准确性方面损失很多。仅记住，在勘探过程中，单纯的旋转将无法估计深度。
在慢动作或没有翻滚和俯仰旋转的应用中，例如平坦区域中的汽车，IMU传感器可能难以初始化。 在这些情况下，如果可能，请使用双目SLAM。否则，至少在训练了CNN的相同类型的环境中，使用CNN从单个图像进行深度估计的最新进展为可靠和真实比例的单目SLAM提供了良好的前景。
